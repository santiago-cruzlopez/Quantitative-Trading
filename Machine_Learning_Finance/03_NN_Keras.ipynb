{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a5f782",
   "metadata": {},
   "source": [
    "## Neural Networks - Keras\n",
    "\n",
    "Functionality through a structured layers approach:\n",
    "\n",
    "- Input Layer: Collects sensory information (e.g., hearing, touching).\n",
    "- Hidden Layers: Two layers process inputs into emotions and feelings.\n",
    "- Output Layer: Generates decisions or actions based on processed inputs.\n",
    "This model offers a simplified view of the complex decision-making processes in the human brain.\n",
    "\n",
    "Most common types of neural networks (neural network trading):\n",
    "\n",
    "- Perceptron\n",
    "- Feed forward neural networks\n",
    "- Multilayer perceptron\n",
    "- Convolutional neural network\n",
    "- Recurrent neural network\n",
    "- Modular neural network\n",
    "\n",
    "Source:\n",
    "- https://blog.quantinsti.com/neural-network-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823bdc7",
   "metadata": {},
   "source": [
    "### How to train a neural network?\n",
    "\n",
    "We'll train a neural network to predict stock prices using historical OHLCV (Open, High, Low, Close, Volume) data. Here’s an overview of the process:\n",
    "\n",
    "1. Training Approaches:\n",
    " - Rule-Based: Define rules for outputs based on inputs.\n",
    " - Model Training: Adjust weights on a dataset to improve predictions.\n",
    "2. Dataset Structure:\n",
    " - Inputs: OHLCV data.\n",
    " - Output: Next day’s Close price (actual y and predicted y').\n",
    "3. Cost Function:\n",
    " - Measures prediction error:\n",
    "  $$ C = \\sum_{}^{}\\frac{1}{2}(\\widehat{y}-y)^{2} $$\n",
    " - Objective: Minimize this cost.\n",
    "4. Training Process:\n",
    " - Compute initial cost with a set of weights.\n",
    " - Adjust weights using backpropagation to reduce the cost iteratively.\n",
    "5. Optimization:\n",
    " - Evaluate cost across multiple weight configurations to find the best ones.\n",
    "\n",
    "By refining weights based on error, the neural network learns to predict stock prices effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7679cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ef946b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta-lib is a technical analysis library, which will be used to compute the RSI and Williams %R. \n",
    "# These will be used as features in order to train our artificial neural network or ANN.\n",
    "# Instructions for the Installation: https://blog.quantinsti.com/install-ta-lib-python/\n",
    "# https://github.com/cgohlke/talib-build/releases -> Install ta_lib-0.6.3-cp313-cp313-win_amd64.whl On Windows win_amd64\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e8212df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1437, 9) (1437,)\n",
      "Testing data shape: (360, 9) (360,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Download stock data\n",
    "price_stock = yf.download('AAPL', start='2017-01-01', end='2024-04-09', auto_adjust=True)\n",
    "\n",
    "# Check if data is downloaded successfully\n",
    "if price_stock.empty:\n",
    "    print(\"Error: No data downloaded. Please check the ticker symbol or internet connection.\")\n",
    "else:\n",
    "    # Preparing the dataset - Inputs\n",
    "    price_stock['H-L'] = price_stock['High'] - price_stock['Low']\n",
    "    price_stock['O-C'] = price_stock['Close'] - price_stock['Open']\n",
    "    price_stock['3day MA'] = price_stock['Close'].shift(1).rolling(window=3).mean()\n",
    "    price_stock['10day MA'] = price_stock['Close'].shift(1).rolling(window=10).mean()\n",
    "    price_stock['30day MA'] = price_stock['Close'].shift(1).rolling(window=30).mean()\n",
    "    price_stock['Std_Dev'] = price_stock['Close'].rolling(5).std()\n",
    "    price_stock['RSI'] = talib.RSI(price_stock['Close'].values.flatten(), timeperiod=9)\n",
    "    price_stock['Williams %R'] = talib.WILLR(\n",
    "        price_stock['High'].values.flatten(),\n",
    "        price_stock['Low'].values.flatten(),\n",
    "        price_stock['Close'].values.flatten(),\n",
    "        7\n",
    "    )\n",
    "\n",
    "    # Output Values - Price Rise or Fall\n",
    "    price_stock['Price_Rise'] = np.where(price_stock['Close'].shift(-1) > price_stock['Close'], 1, 0)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    price_stock = price_stock.dropna()\n",
    "\n",
    "    # Check if the dataset is not empty after preprocessing\n",
    "    if price_stock.empty:\n",
    "        print(\"Error: Dataset is empty after preprocessing. Please check the feature engineering steps.\")\n",
    "    else:\n",
    "        # Define input features (X) and target variable (y)\n",
    "        X = price_stock.iloc[:, 4:-1]\n",
    "        y = price_stock.iloc[:, -1]\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "        # Check if training data is not empty\n",
    "        if X_train.empty or y_train.empty:\n",
    "            print(\"Error: Training data is empty. Please check the data splitting logic.\")\n",
    "        else:\n",
    "            # Standardize the input features\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            sc = StandardScaler()\n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "\n",
    "            # Print shapes of the datasets\n",
    "            print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "            print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
