{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Predictions with LSTM in Python\n",
    "# Long Short-Term Memory (LSTM)\n",
    "# Source: https://www.datacamp.com/tutorial/lstm-python-stock-market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas_datareader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'kaggle' # alphavantage or kaggle\n",
    "\n",
    "if data_source == 'alphavantage':\n",
    "    # ====================== Loading Data from Alpha Vantage ==================================\n",
    "\n",
    "    api_key = 'JYSIYFLVDUKUR91V'\n",
    "\n",
    "    # American Airlines stock market prices\n",
    "    ticker = \"AAL\"\n",
    "\n",
    "    # JSON file with all the stock market data for AAL from the last 20 years\n",
    "    url_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=%s&outputsize=full&apikey=%s\"%(ticker,api_key)\n",
    "\n",
    "    # Save data to this file\n",
    "    file_to_save = 'stock_market_data-%s.csv'%ticker\n",
    "\n",
    "    # If you haven't already saved data,\n",
    "    # Go ahead and grab the data from the url\n",
    "    # And store date, low, high, volume, close, open values to a Pandas DataFrame\n",
    "    if not os.path.exists(file_to_save):\n",
    "        with urllib.request.urlopen(url_string) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            # extract stock market data\n",
    "            data = data['Time Series (Daily)']\n",
    "            df = pd.DataFrame(columns=['Date','Low','High','Close','Open'])\n",
    "            for k,v in data.items():\n",
    "                date = dt.datetime.strptime(k, '%Y-%m-%d')\n",
    "                data_row = [date.date(),float(v['3. low']),float(v['2. high']),\n",
    "                            float(v['4. close']),float(v['1. open'])]\n",
    "                df.loc[-1,:] = data_row\n",
    "                df.index = df.index + 1\n",
    "        print('Data saved to : %s'%file_to_save)        \n",
    "        df.to_csv(file_to_save)\n",
    "\n",
    "    # If the data is already there, just load it from the CSV\n",
    "    else:\n",
    "        print('File already exists. Loading data from CSV')\n",
    "        df = pd.read_csv(file_to_save)\n",
    "\n",
    "else:\n",
    "\n",
    "    # ====================== Loading Data from Kaggle ==================================\n",
    "    # You will be using HP's data. Feel free to experiment with other data.\n",
    "    # But while doing so, be careful to have a large enough dataset and also pay attention to the data normalization\n",
    "    df = pd.read_csv(os.path.join('Stocks','hpq.us.txt'),delimiter=',',usecols=['Date','Open','High','Low','Close'])\n",
    "    print('Loaded data from the Kaggle repository')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
